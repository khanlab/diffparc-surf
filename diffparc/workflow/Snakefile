# ---- begin snakebids boilerplate ----------------------------------------------

import snakebids
from snakebids import bids


configfile: "config/snakebids.yml"


# writes inputs_config.yml and updates config dict
inputs = snakebids.generate_inputs(
    bids_dir=config["bids_dir"],
    pybids_inputs=config["pybids_inputs"],
    pybids_database_dir=config.get("pybids_db_dir"),
    pybids_reset_database=config.get("pybids_db_reset"),
    derivatives=config["derivatives"],
    participant_label=config["participant_label"],
    exclude_participant_label=config["exclude_participant_label"],
    use_bids_inputs=True,
)


# this adds constraints to the bids naming
wildcard_constraints:
    **snakebids.get_wildcard_constraints(config["pybids_inputs"]),


# ---- end snakebids boilerplate ------------------------------------------------


report: "../workflow/report/workflow.rst"


subj_wildcards = inputs.subj_wildcards
input_wildcards = inputs.input_wildcards
input_zip_lists = inputs.input_zip_lists
input_path = inputs.input_path

# ------ subj_zip_list ---- (consider adding this logic to snakebids) ---------
# create a subj_zip_list bids_input var to loop over subjects/sessions where
# *all* the pybids inputs are present (e.g. T1w and dwi both present)
#
# does this by performing a set intersection of the (subject+session only) zip lists for different modalities

subj_set_intersection = None
subj_set_union = None  # union not really used except for finding set union - intersection (skipped subjects)
subj_zip_list = None

for bidsinput in config["pybids_inputs"].keys():
    zipl = inputs.input_zip_lists[bidsinput]
    if "session" in zipl:
        # has session, so we have to zip, then use set to remove duplicates
        subj_set = set(zip(zipl["subject"], zipl["session"]))
    else:
        # does not have session, so we can remove duplicates easily by using set
        subj_set = set(zipl["subject"])

    subj_set_intersection = (
        subj_set
        if subj_set_intersection == None
        else subj_set.intersection(subj_set_intersection)
    )
    subj_set_union = (
        subj_set if subj_set_union == None else subj_set.union(subj_set_union)
    )


subj_set_difference = subj_set_union - subj_set_intersection
# print(f'Skipping following (subjects/sessions) since they are missing one of the required bids inputs: {subj_set_difference}')

if "session" in zipl:
    (subzip, seszip) = zip(*list(subj_set_intersection))  # zip it up again
    subj_zip_list = {
        "subject": subzip,
        "session": seszip,
    }  # create the new subj_zip_list

else:
    subj_zip_list = {"subject": list(subj_set_intersection)}

# ------------------------------------------------------------------------------

# set the default bids root for output files
root = config["root"]


def get_eddy_quad_all():
    if config["eddy_no_quad"]:
        return {}
    else:
        return {
            "eddy_qc": expand(
                bids(
                    root=root, datatype="dwi", suffix="eddy.qc_pages", **subj_wildcards
                ),
                zip,
                **subj_zip_list
            )
        }


def get_bedpost_all():
    if config["no_bedpost"]:
        return {}
    else:
        return {
            "bedpost": expand(
                bids(
                    root=root,
                    datatype="dwi",
                    suffix="diffusion.bedpostX",
                    desc="eddy",
                    space="T1w",
                    res=config["resample_dwi"]["resample_scheme"],
                    **subj_wildcards
                ),
                zip,
                **subj_zip_list
            )
        }


rule all_diffparc:
    input:
        conn_nii=expand(
            expand(
                bids(
                    root=root,
                    datatype="dwi",
                    hemi="{hemi}",
                    space="{template}",
                    desc="{targets}",
                    label="{seed}",
                    seedpervox="{seedpervox}",
                    segtype="maxprob",
                    suffix="dseg.nii.gz",
                    **subj_wildcards,
                ),
                template=config["template"],
                targets=config["targets"].keys(),
                seed=config["seeds"].keys(),
                seedpervox=config["seeds_per_voxel"],
                hemi=config["hemispheres"],
                allow_missing=True,
            ),
            zip,
            **subj_zip_list,
        ),


rule all_surfmorph:
    input:
        surfdisp=expand(
            expand(
                bids(
                    root=root,
                    **subj_wildcards,
                    from_="{template}",
                    datatype="surf",
                    label="{seed}",
                    parcel="{targets}",
                    seedspervertex="{seedspervertex}",
                    suffix="{metric}.pscalar.nii",
                ),
                template=config["template"],
                hemi=config["hemispheres"],
                seed=config["seeds"].keys(),
                targets=config["targets"].keys(),
                seedspervertex=config["seeds_per_vertex"],
                metric=config["surface_metrics"],
                allow_missing=True,
            ),
            zip,
            **subj_zip_list,
        ),


rule all_group_dscalar:
    input:
        cifti_dscalar_group=expand(
            bids(
                root=root,
                subject="group",
                from_="{template}",
                datatype="surf",
                label="{seed}",
                suffix="inout.dscalar.nii",
            ),
            template=config["template"],
            seed=config["seeds"].keys(),
        ),


rule all_template:
    input:
        surf_normals=expand(
            os.path.join(
                workflow.basedir,
                "..",
                "resources/tpl-{template}/tpl-{template}_hemi-{hemi}_label-{seed}_normals.shape.gii",
            ),
            template=config["template"],
            hemi=config["hemispheres"],
            seed=config["seeds"],
        ),


rule all_preprocdwi:
    input:
        **get_eddy_quad_all(),
        **get_bedpost_all(),
        mask_qc=expand(
            bids(root="qc", suffix="mask.png", desc="brain", **subj_wildcards),
            zip,
            **subj_zip_list
        ),
        reg_qc=expand(
            bids(
                root="qc", suffix="reg.png", from_="dwiref", to="T1w", **subj_wildcards
            ),
            zip,
            **subj_zip_list
        ),
        dtifit=expand(
            bids(
                root=root,
                datatype="dwi",
                suffix="dtifit",
                desc="eddy",
                space="T1w",
                res=config["resample_dwi"]["resample_scheme"],
                **subj_wildcards
            ),
            zip,
            **subj_zip_list
        ),


rule all_legacy_csv:
    input:
        csv=expand(
            bids(
                root=root,
                subject="group",
                datatype="tabular",
                from_="{template}",
                desc="{targets}",
                label="{seed}",
                seedspervertex="{seedspervertex}",
                method="{method}",
                form="{form}",
                suffix="{suffix}.csv",
            ),
            template=config["template"],
            targets=config["targets"].keys(),
            seedspervertex=config["seeds_per_vertex"],
            seed=config["seeds"],
            method=config["methods"],
            form="legacy",
            suffix=config["surface_metrics"],
        ),


def get_subj_tables_legacy():
    csvs = []
    for seed in config["select_seeds"]:
        csvs.extend(
            expand(
                expand(
                    bids(
                        root=root,
                        datatype="tabular",
                        from_="{template}",
                        desc="{targets}",
                        label="{seed}",
                        seedspervertex="{seedspervertex}",
                        method="{method}",
                        form="{form}",
                        suffix="{suffix}.csv",
                        **subj_wildcards,
                    ),
                    template=config["template"],
                    hemi=config["hemispheres"],
                    seed=seed,
                    targets=config["seeds"][seed]["targets"],
                    seedspervertex=config["seeds"][seed]["seeds_per_vertex"],
                    method=config["methods"],
                    form=["legacy"],
                    suffix=config["surface_metrics"],
                    allow_missing=True,
                ),
                zip,
                **subj_zip_list,
            )
        )
    return csvs


rule all_subj_tables_legacy:
    input:
        get_subj_tables_legacy(),


rule all:
    input:
        rules.all_subj_tables_legacy.input,
    default_target: True


include: "rules/common.smk"
include: "rules/prepdwi.smk"
include: "rules/reg_dwi_to_t1.smk"
include: "rules/masking_bet_from-b0.smk"
include: "rules/masking_b0_to_template.smk"
include: "rules/reg_t1_to_template.smk"
include: "rules/seg_t1_brain_tissue.smk"
include: "rules/diffparc.smk"
include: "rules/mrtrix.smk"
include: "rules/motioncorr.smk"
include: "rules/surfmorph.smk"
include: "rules/surftrack.smk"
include: "rules/synthseg.smk"
include: "rules/tables.smk"
include: "rules/sampledti.smk"
include: "rules/bedpost.smk"
include: "rules/probtrack_surf.smk"
include: "rules/parcbundles.smk"
